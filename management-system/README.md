# ğŸª Sistema de Gerenciamento de InventÃ¡rio DistribuÃ­do

![Java](https://img.shields.io/badge/Java-21-orange)
![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2.0-brightgreen)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-7.4-red)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue)
![Redis](https://img.shields.io/badge/Redis-7.2-red)
![Docker](https://img.shields.io/badge/Docker-Required-blue)
![Prometheus](https://img.shields.io/badge/Prometheus-2.47-orange)
![Grafana](https://img.shields.io/badge/Grafana-10.1-yellow)
![License](https://img.shields.io/badge/License-MIT-green)

Sistema de gerenciamento de inventÃ¡rio distribuÃ­do de alta disponibilidade baseado em **arquitetura de microserviÃ§os** com **controle de concorrÃªncia distribuÃ­da**, **sistema de resiliÃªncia DLQ (Dead Letter Queue)**, **observabilidade completa** e **operaÃ§Ã£o offline-first**.

## ğŸš€ Quick Start (5 minutos)

```bash
# 1. Clone e acesse o diretÃ³rio
git clone <repository-url>
cd management-system

# 2. Execute o sistema completo
docker-compose up --build -d

# 3. Aguarde inicializaÃ§Ã£o (2-3 minutos)
echo "â³ Aguardando serviÃ§os ficarem prontos..."
sleep 180

# 4. Teste bÃ¡sico de funcionamento
./scripts/test-basic.sh

# 5. Abra a API no navegador
open http://localhost:8081/store-service/swagger-ui.html
```

**âš¡ URLs de Acesso RÃ¡pido:**
- ğŸª Store API: http://localhost:8081/store-service/swagger-ui.html
- ğŸ¢ Central API: http://localhost:8082/central-inventory-service/swagger-ui.html
- ğŸ“ˆ Grafana: http://localhost:3000 (admin/grafana123)
- ğŸ” Prometheus: http://localhost:9090

â¡ï¸ **Para instruÃ§Ãµes detalhadas, consulte:** [RUN.md](RUN.md)

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
- [ğŸš€ InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ğŸ§ª Testes](#-testes)
- [ğŸŒ APIs](#-apis)
- [ğŸ“Š Monitoramento](#-monitoramento)
- [ğŸ“š DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

### âœ¨ CaracterÃ­sticas e Diferenciais TÃ©cnicos

#### ğŸš€ **Performance e Escalabilidade**
- **âš¡ Baixa LatÃªncia**: < 50ms para operaÃ§Ãµes locais, < 200ms para distribuÃ­das
- **ğŸ”„ Alta Throughput**: 10.000+ ops/sec por instÃ¢ncia
- **ğŸ“ˆ Auto Scaling**: Baseado em CPU, MemÃ³ria e Queue Depth
- **ğŸŒ Multi-Region**: Suporte a operaÃ§Ã£o em mÃºltiplas regiÃµes

#### ğŸ›¡ï¸ **ResiliÃªncia e Confiabilidade**
- **ğŸ’¾ Zero Data Loss**: Sistema DLQ com persistÃªncia garantida
- **ï¿½ Auto Recovery**: RecuperaÃ§Ã£o automÃ¡tica a cada 5 minutos
- **âš¡ Circuit Breaker**: ProteÃ§Ã£o contra cascading failures
- **ğŸ¯ Graceful Degradation**: OperaÃ§Ã£o offline-first

#### ğŸ” **Controle de ConcorrÃªncia**
- **ğŸ”’ Optimistic Locking**: Controle de versÃ£o distribuÃ­do
- **âš¡ Retry Inteligente**: Backoff exponencial com jitter
- **ğŸª Multi-Store**: Suporte nativo a mÃºltiplas lojas
- **ğŸ“Š JSONB Storage**: Dados eficientes no PostgreSQL

#### ğŸ“Š **Observabilidade Completa**
- **ğŸ“ˆ MÃ©tricas Real-time**: Prometheus + Grafana
- **ğŸ” Distributed Tracing**: Correlation IDs
- **ğŸ“± Alerting**: Baseado em SLA/SLO
- **ğŸ›ï¸ Admin APIs**: Controle total do sistema

### ğŸª **MicroserviÃ§os e Responsabilidades**

| **ServiÃ§o** | **Porta** | **FunÃ§Ã£o Principal** | **CaracterÃ­sticas** |
|-------------|-----------|---------------------|-------------------|
| **ğŸª Store Service** | 8081 | InventÃ¡rio local por loja | â€¢ OperaÃ§Ã£o offline-first<br/>â€¢ Cache L1/L2<br/>â€¢ DLQ integrado<br/>â€¢ Optimistic Locking |
| **ğŸ¢ Central Service** | 8082 | VisÃ£o global e reconciliaÃ§Ã£o | â€¢ AgregaÃ§Ã£o multi-loja<br/>â€¢ RelatÃ³rios consolidados<br/>â€¢ Event Sourcing<br/>â€¢ Conflict Resolution |

### ğŸ¯ **Casos de Uso Cobertos**

#### **Store Service (OperaÃ§Ãµes Locais)**
```yaml
Consulta de InventÃ¡rio:
  - âœ… Listar produtos disponÃ­veis por loja
  - âœ… Consultar produto especÃ­fico com cache
  - âœ… Verificar disponibilidade em tempo real
  - âœ… Busca por categoria/filtros

GestÃ£o de Reservas:
  - âœ… Reservar produtos para carrinho
  - âœ… Confirmar venda (commit)
  - âœ… Cancelar reserva com motivo
  - âœ… ExpiraÃ§Ã£o automÃ¡tica de reservas

OperaÃ§Ãµes de Estoque:
  - âœ… Atualizar quantidades
  - âœ… Recebimento de mercadorias
  - âœ… Ajustes de inventÃ¡rio
  - âœ… MovimentaÃ§Ã£o entre locais
```

#### **Central Service (OperaÃ§Ãµes Globais)**
```yaml
VisÃ£o Consolidada:
  - âœ… InventÃ¡rio global por SKU
  - âœ… InventÃ¡rio por loja/regiÃ£o
  - âœ… RelatÃ³rios de movimentaÃ§Ã£o
  - âœ… Analytics e BI

ReconciliaÃ§Ã£o:
  - âœ… Resolver conflitos entre lojas
  - âœ… SincronizaÃ§Ã£o forÃ§ada
  - âœ… Audit trail completo
  - âœ… CorreÃ§Ã£o de inconsistÃªncias
```

## ğŸ—ï¸ Arquitetura TÃ©cnica Completa

### ğŸ¯ Diagrama de Arquitetura com Sistema de ResiliÃªncia

```mermaid
graph TB
    subgraph "ğŸ‘¥ Clientes"
        A1[Store App - Loja 1]
        A2[Store App - Loja 2]
        A3[Admin Portal]
        A4[External APIs]
    end

    subgraph "ğŸŒ API Gateway"
        GW[Load Balancer / API Gateway]
    end

    subgraph "ğŸª MicroserviÃ§os"
        subgraph "Store Services"
            SS1[Store Service 1<br/>:8081]
            SS2[Store Service 2<br/>:8082]
            SS3[Store Service N<br/>:808X]
        end
        
        subgraph "Central Service"
            CS[Central Inventory<br/>Service :8082]
        end
        
        subgraph "ğŸ›¡ï¸ Sistema DLQ"
            DLQ1[DLQ Store 1]
            DLQ2[DLQ Store 2]
            DLQ3[DLQ Store N]
        end
    end

    subgraph "ğŸ”„ Message Streaming"
        subgraph "Apache Kafka"
            K1[inventory-update]
            K2[inventory-reserve]
            K3[inventory-commit]
            K4[inventory-cancel]
        end
    end

    subgraph "ğŸ’¾ Camada de Dados"
        subgraph "Bancos de Dados"
            PG[(PostgreSQL<br/>:5432)]
            RD[(Redis Cache<br/>:6379)]
        end
        
        subgraph "Schemas"
            PG1[store_inventory_db]
            PG2[central_inventory_db]
            PG3[dlq_events_db]
        end
    end

    subgraph "ğŸ“Š Observabilidade"
        PROM[Prometheus<br/>:9090]
        GRAF[Grafana<br/>:3000]
        
        subgraph "Dashboards"
            D1[Application Metrics]
            D2[Business Metrics]
            D3[Infrastructure]
            D4[DLQ Monitoring]
        end
    end

    %% ConexÃµes dos clientes
    A1 --> GW
    A2 --> GW
    A3 --> GW
    A4 --> GW

    %% Gateway para serviÃ§os
    GW --> SS1
    GW --> SS2
    GW --> SS3
    GW --> CS

    %% ComunicaÃ§Ã£o entre serviÃ§os
    SS1 -.->|Events| K1
    SS2 -.->|Events| K2
    SS3 -.->|Events| K3
    CS -.->|Events| K4

    %% Sistema DLQ
    SS1 -.->|Falha Kafka| DLQ1
    SS2 -.->|Falha Kafka| DLQ2
    SS3 -.->|Falha Kafka| DLQ3

    %% Dados
    SS1 --> PG1
    SS2 --> PG1
    SS3 --> PG1
    CS --> PG2
    DLQ1 --> PG3
    DLQ2 --> PG3
    DLQ3 --> PG3

    %% Cache
    SS1 --> RD
    SS2 --> RD
    SS3 --> RD
    CS --> RD

    %% Monitoramento
    SS1 --> PROM
    SS2 --> PROM
    SS3 --> PROM
    CS --> PROM
    PROM --> GRAF
    GRAF --> D1
    GRAF --> D2
    GRAF --> D3
    GRAF --> D4

    %% Estilos
    classDef service fill:#e1f5fe
    classDef database fill:#f3e5f5
    classDef messaging fill:#fff3e0
    classDef monitoring fill:#e8f5e8
    classDef dlq fill:#ffebee
    
    class SS1,SS2,SS3,CS service
    class PG,RD,PG1,PG2,PG3 database
    class K1,K2,K3,K4 messaging
    class PROM,GRAF,D1,D2,D3,D4 monitoring
    class DLQ1,DLQ2,DLQ3 dlq
```

### ğŸ› ï¸ Componentes da Infraestrutura

| **Componente** | **VersÃ£o** | **Porta** | **FunÃ§Ã£o** | **Recursos** |
|----------------|------------|-----------|------------|-------------|
| **Java Runtime** | 21 (LTS) | - | Runtime da aplicaÃ§Ã£o | Performance otimizada, GC moderno |
| **Spring Boot** | 3.2.0 | - | Framework principal | Auto-configuraÃ§Ã£o, Actuator |
| **PostgreSQL** | 15-alpine | 5432 | Banco principal | JSONB, Particionamento, MVCC |
| **Redis** | 7.2-alpine | 6379 | Cache distribuÃ­do | Estruturas avanÃ§adas, PersistÃªncia |
| **Apache Kafka** | 7.4.0 | 9092,29092 | Message Streaming | Alta throughput, Durabilidade |
| **Zookeeper** | 7.4.0 | 2181 | CoordenaÃ§Ã£o Kafka | Metadata, Leader Election |
| **Prometheus** | 2.47.0 | 9090 | MÃ©tricas | Time-series DB, PromQL |
| **Grafana** | 10.1.0 | 3000 | VisualizaÃ§Ã£o | Dashboards, Alerting |
| **Store Service** | 1.0.0 | 8081 | API InventÃ¡rio Local | DLQ, Optimistic Locking |
| **Central Service** | 1.0.0 | 8082 | API InventÃ¡rio Global | AgregaÃ§Ã£o, ReconciliaÃ§Ã£o |

### ï¿½ Stack TecnolÃ³gica Detalhada

#### **Backend Technologies**
```yaml
Core Framework:
  - Java: 21 (Virtual Threads, Pattern Matching, Records)
  - Spring Boot: 3.2.0 (Native Support, Observability)
  - Spring Data JPA: 3.2.0 (Repository Pattern, Auditing)
  - Spring Kafka: 3.1.0 (Event Streaming, Error Handling)
  - Spring Data Redis: 3.2.0 (Caching, Session Storage)

Arquitetura:
  - Hexagonal Architecture (Ports & Adapters)
  - Event-Driven Architecture
  - CQRS Pattern (Command Query Responsibility Segregation)
  - Saga Pattern para transaÃ§Ãµes distribuÃ­das
  - Circuit Breaker Pattern (Resilience4j)
```

#### **Data Layer**
```yaml
Bancos de Dados:
  Primary: PostgreSQL 15
    - JSONB para dados flexÃ­veis
    - Particionamento por loja
    - Ãndices otimizados
    - Connection Pooling (HikariCP)
  
  Cache: Redis 7.2
    - Cache L2 (Hibernate)
    - Session Storage
    - Rate Limiting
    - Pub/Sub para notificaÃ§Ãµes

MigraÃ§Ãµes:
  - Flyway: Versionamento de schema
  - Rollback automÃ¡tico
  - ValidaÃ§Ã£o de integridade
```

#### **Message Streaming**
```yaml
Apache Kafka 7.4:
  Topics:
    - inventory-update: AtualizaÃ§Ãµes de estoque
    - inventory-reserve: Reservas de produtos
    - inventory-commit: ConfirmaÃ§Ãµes de venda
    - inventory-cancel: Cancelamentos
    - dlq-events: Dead Letter Queue

  ConfiguraÃ§Ãµes:
    - Replication Factor: 1 (dev) / 3 (prod)
    - Partitions: Por loja/regiÃ£o
    - Retention: 7 dias
    - Compression: LZ4
```

#### **Observability Stack**
```yaml
MÃ©tricas:
  - Micrometer: InstrumentaÃ§Ã£o
  - Prometheus: Coleta e armazenamento
  - Custom Metrics: Business KPIs

Dashboards:
  - Grafana: VisualizaÃ§Ã£o avanÃ§ada
  - Application Performance Monitoring
  - Infrastructure Monitoring
  - Business Intelligence Dashboards

Logging:
  - SLF4J + Logback
  - Structured Logging (JSON)
  - Correlation IDs
  - Log Aggregation
```

## ğŸ›¡ï¸ Sistema de ResiliÃªncia e Controle de ConcorrÃªncia

### ğŸ”’ **Controle de ConcorrÃªncia DistribuÃ­da**

#### **Problema Resolvido**
Sistema que gerencia **mÃºltiplas lojas** (store-service-1, store-service-2, store-service-N...) atualizando simultaneamente:
- ğŸª **InventÃ¡rio intra-loja**: Controle local por loja
- ğŸŒ **InventÃ¡rio inter-lojas**: VisÃ£o global consolidada

#### **SoluÃ§Ã£o TÃ©cnica Implementada**

```java
// Store Service - Controle INTRA-LOJA
@Entity
public class ProductEntity {
    @Version
    @Column(name = "version", nullable = false)
    private Long version; // Optimistic Locking JPA
}

// Central Service - Controle INTER-LOJAS  
@Entity
@Table(name = "global_inventory")
public class GlobalInventoryEntity {
    @Version
    private Long version; // Controle de versÃ£o global
    
    @JdbcTypeCode(SqlTypes.JSON)
    @Column(name = "store_quantities", columnDefinition = "jsonb")
    private String storeQuantitiesJson; // Dados agregados JSONB
}

// Retry Strategy com Backoff Exponencial
@Retryable(
    maxAttempts = 5,
    backoff = @Backoff(delay = 100, multiplier = 2.0, maxDelay = 5000),
    include = {OptimisticLockingFailureException.class}
)
public Product updateProductQuantity(String sku, Integer quantity) {
    // OperaÃ§Ã£o com retry automÃ¡tico em conflitos
}
```

#### **Estrutura JSONB Multi-Store**
```json
{
  "STORE-001": {
    "quantity": 15,
    "reservedQuantity": 2,
    "lastUpdated": "2025-09-01T10:30:00Z",
    "version": 1
  },
  "STORE-002": {
    "quantity": 8, 
    "reservedQuantity": 1,
    "lastUpdated": "2025-09-01T10:35:00Z",
    "version": 3
  },
  "STORE-003": {
    "quantity": 12,
    "reservedQuantity": 0,
    "lastUpdated": "2025-09-01T10:40:00Z", 
    "version": 2
  }
}
```

### ğŸ›¡ï¸ **Dead Letter Queue (DLQ) System**

#### **Fluxo de ResiliÃªncia Completo**

```mermaid
flowchart TD
    A[Business Operation<br/>Reserve/Commit/Update] --> B{Try Kafka Direct}
    
    B -->|âœ… Success| C[Event Published<br/>to Kafka Topic]
    B -->|âŒ Kafka Offline| D[ğŸ›¡ï¸ Store in DLQ<br/>PostgreSQL Table]
    
    D --> E[Mark Event as PENDING]
    E --> F[Continue Business Operation<br/>âš¡ Zero Downtime]
    
    G[ğŸ¤– Auto Recovery Job<br/>Every 5 minutes] --> H{Load Pending Events}
    H --> I[Retry Failed Events<br/>Exponential Backoff]
    
    I -->|âœ… Success| J[Mark as SUCCEEDED<br/>Remove from DLQ]
    I -->|âŒ Still Failing| K[Increment Retry Count<br/>Back to PENDING]
    
    K --> L{Max Retries<br/>Reached?}
    L -->|No| I
    L -->|Yes| M[Mark as FAILED<br/>Alert Admin]
    
    J --> N[ğŸ§¹ Auto Cleanup<br/>Remove Old Events]
    
    style D fill:#ffebee
    style G fill:#e8f5e8
    style M fill:#ffcdd2
    style N fill:#e0f2f1
```

#### **ConfiguraÃ§Ã£o de ResiliÃªncia**
```yaml
app:
  resilience:
    dlq:
      enabled: true
      auto-recovery:
        enabled: true
        interval: "PT5M"              # A cada 5 minutos
        batch-size: 100               # Processar 100 eventos por vez
      retry:
        max-attempts: 10              # MÃ¡ximo 10 tentativas
        initial-delay: "PT1S"         # Delay inicial: 1 segundo
        max-delay: "PT5M"            # Delay mÃ¡ximo: 5 minutos
        multiplier: 2.0              # Backoff exponencial
      cleanup:
        retention-days: 7            # Manter eventos por 7 dias
        succeeded-events: "PT1H"     # Limpar sucessos apÃ³s 1 hora
    
    circuit-breaker:
      kafka:
        enabled: true
        failure-threshold: 5         # Abrir apÃ³s 5 falhas
        timeout: "PT1M"             # Tentar novamente apÃ³s 1 minuto
        half-open-max-calls: 3      # 3 chamadas em half-open
```

### ğŸ” **SeguranÃ§a e Compliance**

#### **SeguranÃ§a de Dados**
```yaml
Encryption:
  - âœ… TLS 1.3 para todas as comunicaÃ§Ãµes
  - âœ… Database encryption at rest
  - âœ… Redis AUTH com senha forte
  - âœ… Kafka SASL/SCRAM (produÃ§Ã£o)

Data Privacy:
  - âœ… LGPD/GDPR compliance
  - âœ… PII data encryption
  - âœ… Audit trail completo
  - âœ… Data retention policies

Access Control:
  - âœ… Network policies (Docker)
  - âœ… Service-to-service authentication
  - âœ… API rate limiting
  - âœ… Admin endpoints protegidos
```

#### **Disaster Recovery**
```yaml
Backup Strategy:
  PostgreSQL:
    - Backup diÃ¡rio completo
    - WAL continuous archiving
    - Point-in-time recovery
    
  Kafka:
    - Replication factor: 3 (prod)
    - Cross-region replication
    - Topic backup to S3
    
  Redis:
    - AOF persistence
    - RDB snapshots
    - Master-slave replication

Recovery Procedures:
  - RTO: 15 minutos (Recovery Time Objective)
  - RPO: 5 minutos (Recovery Point Objective)  
  - Automated failover
  - Manual override procedures
```

## ï¿½ ConfiguraÃ§Ã£o e Deployment

### ğŸ³ **Container Infrastructure**

#### **Docker Compose Services**
```yaml
Infraestrutura Base:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    ports: ["2181:2181"]
    volumes: [zookeeper_data, zookeeper_logs]
    
  kafka:
    image: confluentinc/cp-kafka:7.4.0  
    ports: ["9092:9092", "29092:29092"]
    depends_on: [zookeeper]
    volumes: [kafka_data]
    
  postgres:
    image: postgres:15-alpine
    ports: ["5432:5432"]
    volumes: [postgres_data, ./infrastructure/postgres/init]
    environment:
      POSTGRES_DB: inventory_db
      POSTGRES_USER: inventory_user
      
  redis:
    image: redis:7.2-alpine
    ports: ["6379:6379"] 
    command: redis-server --appendonly yes --requirepass inventorypass123
    volumes: [redis_data]

Monitoramento:
  prometheus:
    image: prom/prometheus:v2.47.0
    ports: ["9090:9090"]
    volumes: [./infrastructure/prometheus/prometheus.yml, prometheus_data]
    
  grafana:
    image: grafana/grafana:10.1.0
    ports: ["3000:3000"]
    volumes: [grafana_data, ./infrastructure/grafana]
    environment:
      GF_SECURITY_ADMIN_PASSWORD: grafana123

AplicaÃ§Ãµes:
  store-service:
    build: ./store-service
    ports: ["8081:8081"]
    depends_on: [kafka, redis, postgres]
    environment:
      SPRING_PROFILES_ACTIVE: local
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      
  central-inventory-service:
    build: ./central-inventory-service
    ports: ["8082:8082"] 
    depends_on: [postgres, kafka, redis]
```

### âš™ï¸ **ConfiguraÃ§Ãµes de Ambiente**

#### **Profiles Spring Boot**
```yaml
# application-local.yml (desenvolvimento)
spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/inventory_db
    username: inventory_user
    password: inventory_password
    
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      retries: 5
      acks: all
      
  redis:
    host: localhost
    port: 6379
    password: inventorypass123

# application-docker.yml (containers)  
spring:
  datasource:
    url: jdbc:postgresql://postgres:5432/inventory_db
    
  kafka:
    bootstrap-servers: kafka:29092
    
  redis:
    host: redis
    
# application-prod.yml (produÃ§Ã£o)
spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    security:
      protocol: SASL_SSL
      
  datasource:
    url: jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
    username: ${DB_USER}
    password: ${DB_PASSWORD}
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
```

### ğŸ—ï¸ **Build e Deployment**

#### **Maven Multi-Module Build**
```xml
<!-- parent pom.xml -->
<modules>
    <module>store-service</module>
    <module>central-inventory-service</module>
</modules>

<!-- Comandos de build -->
mvn clean compile                    # CompilaÃ§Ã£o
mvn clean test                      # Testes unitÃ¡rios  
mvn clean verify                    # Testes de integraÃ§Ã£o
mvn clean package                   # Gerar JARs
mvn clean package -DskipTests       # Build rÃ¡pido
```

#### **Docker Build Otimizado**
```dockerfile
# Multi-stage build para reduzir tamanho da imagem
FROM maven:3.9-openjdk-21 AS builder
WORKDIR /app
COPY pom.xml .
COPY src src
RUN mvn clean package -DskipTests

FROM openjdk:21-jre-slim
WORKDIR /app
COPY --from=builder /app/target/*.jar app.jar

# OtimizaÃ§Ãµes JVM
ENV JAVA_OPTS="-Xmx1024m -Xms512m -XX:+UseG1GC -XX:+UseStringDeduplication"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8081/actuator/health || exit 1

EXPOSE 8081
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### âš¡ **Performance Tuning**

#### **JVM Configuration**
```bash
# OtimizaÃ§Ãµes de produÃ§Ã£o
JAVA_OPTS="
  -Xmx2048m -Xms1024m
  -XX:+UseG1GC
  -XX:MaxGCPauseMillis=200
  -XX:+UseStringDeduplication
  -XX:+OptimizeStringConcat
  -Dspring.jpa.hibernate.ddl-auto=validate
  -Dspring.datasource.hikari.maximum-pool-size=20
  -Dspring.kafka.producer.batch-size=32768
  -Dspring.kafka.producer.linger-ms=10
"
```

#### **Database Tuning**
```sql
-- PostgreSQL otimizaÃ§Ãµes
-- postgresql.conf
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
max_connections = 200

-- Ãndices otimizados
CREATE INDEX CONCURRENTLY idx_products_sku_store ON products (sku, store_id);
CREATE INDEX CONCURRENTLY idx_reservations_expires_at ON reservations (expires_at) WHERE status = 'ACTIVE';
CREATE INDEX CONCURRENTLY idx_failed_events_status_created ON failed_events (status, created_at);
```

#### **Kafka Configuration**
```yaml
# kafka optimization
bootstrap-servers: kafka:29092
producer:
  acks: all
  retries: 5
  batch-size: 32768
  linger-ms: 10
  compression-type: lz4
  max-in-flight-requests-per-connection: 5
  enable-idempotence: true
  
consumer:
  auto-offset-reset: earliest
  enable-auto-commit: false
  max-poll-records: 100
  fetch-min-size: 1024
```

## ï¿½ Sistema de Monitoramento e Observabilidade

### ğŸª **Store Service APIs**

#### **1. Consulta de Produtos**

```bash
# Listar todos os produtos da loja
curl -X GET "http://localhost:8081/api/v1/store/STORE-001/inventory/products" \
  -H "Accept: application/json" | jq

# Resposta esperada:
[
  {
    "sku": "NOTEBOOK-001",
    "name": "Notebook Dell XPS 13",
    "category": "ELECTRONICS", 
    "quantity": 15,
    "reservedQuantity": 2,
    "availableQuantity": 13,
    "price": 4999.99,
    "lastUpdated": "2025-09-01T10:30:00Z"
  },
  {
    "sku": "SMARTPHONE-001", 
    "name": "iPhone 15 Pro",
    "category": "ELECTRONICS",
    "quantity": 8,
    "reservedQuantity": 1,
    "availableQuantity": 7,
    "price": 7999.99,
    "lastUpdated": "2025-09-01T09:45:00Z"
  }
]
```

```bash
# Consultar produto especÃ­fico
curl -X GET "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001" \
  -H "Accept: application/json" | jq

# Busca com filtros
curl -X GET "http://localhost:8081/api/v1/store/STORE-001/inventory/products/search?category=ELECTRONICS&minQuantity=5" \
  -H "Accept: application/json" | jq
```

#### **2. OperaÃ§Ãµes de Reserva**

```bash
# Reservar produto para carrinho
curl -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/reserve" \
  -H "Content-Type: application/json" \
  -H "Accept: application/json" \
  -d '{
    "quantity": 2,
    "customerId": "customer-789",
    "reservationDuration": "PT30M",
    "reason": "Shopping cart reservation"
  }' | jq

# Resposta esperada:
{
  "reservationId": "res-12345-abc",
  "sku": "NOTEBOOK-001",
  "quantity": 2,
  "customerId": "customer-789",
  "status": "ACTIVE",
  "expiresAt": "2025-09-01T11:00:00Z",
  "createdAt": "2025-09-01T10:30:00Z"
}
```

```bash
# Confirmar venda (commit da reserva)
curl -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/commit" \
  -H "Content-Type: application/json" \
  -d '{
    "reservationId": "res-12345-abc",
    "customerId": "customer-789",
    "saleId": "sale-98765",
    "paymentMethod": "CREDIT_CARD"
  }' | jq

# Resposta esperada:
{
  "commitId": "commit-67890-def",
  "reservationId": "res-12345-abc", 
  "status": "COMMITTED",
  "quantitySold": 2,
  "revenue": 9999.98,
  "committedAt": "2025-09-01T10:35:00Z"
}
```

```bash
# Cancelar reserva
curl -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/cancel" \
  -H "Content-Type: application/json" \
  -d '{
    "reservationId": "res-12345-abc",
    "customerId": "customer-789", 
    "reason": "Customer changed mind",
    "cancelledBy": "customer"
  }' | jq

# Resposta esperada:
{
  "cancellationId": "cancel-11111-ghi",
  "reservationId": "res-12345-abc",
  "status": "CANCELLED",
  "reason": "Customer changed mind",
  "quantityReleased": 2,
  "cancelledAt": "2025-09-01T10:40:00Z"
}
```

### ğŸ¢ **Central Inventory Service APIs**

#### **3. VisÃ£o Global de InventÃ¡rio**

```bash
# InventÃ¡rio global por SKU (todas as lojas)
curl -X GET "http://localhost:8082/api/v1/inventory/global/NOTEBOOK-001" \
  -H "Accept: application/json" | jq

# Resposta esperada:
{
  "sku": "NOTEBOOK-001",
  "name": "Notebook Dell XPS 13",
  "totalQuantity": 45,
  "totalReservedQuantity": 8,
  "totalAvailableQuantity": 37,
  "storeBreakdown": {
    "STORE-001": {
      "quantity": 15,
      "reservedQuantity": 2,
      "availableQuantity": 13,
      "lastUpdated": "2025-09-01T10:30:00Z"
    },
    "STORE-002": {
      "quantity": 18,
      "reservedQuantity": 3,
      "availableQuantity": 15,
      "lastUpdated": "2025-09-01T10:25:00Z"
    },
    "STORE-003": {
      "quantity": 12,
      "reservedQuantity": 3,
      "availableQuantity": 9,
      "lastUpdated": "2025-09-01T10:20:00Z"
    }
  },
  "aggregatedAt": "2025-09-01T10:35:00Z"
}
```

```bash
# InventÃ¡rio de uma loja especÃ­fica (visÃ£o central)
curl -X GET "http://localhost:8082/api/v1/inventory/stores/STORE-001/products" \
  -H "Accept: application/json" | jq

# Top produtos mais vendidos (Ãºltimos 7 dias)
curl -X GET "http://localhost:8082/api/v1/inventory/analytics/top-products?days=7&limit=10" \
  -H "Accept: application/json" | jq
```

#### **4. OperaÃ§Ãµes de ReconciliaÃ§Ã£o**

```bash
# ForÃ§ar reconciliaÃ§Ã£o manual
curl -X POST "http://localhost:8082/api/v1/inventory/reconcile" \
  -H "Content-Type: application/json" \
  -d '{
    "storeId": "STORE-001",
    "sku": "NOTEBOOK-001",
    "reason": "Manual sync after system maintenance"
  }' | jq

# Resposta esperada:
{
  "reconciliationId": "recon-55555-jkl",
  "storeId": "STORE-001", 
  "sku": "NOTEBOOK-001",
  "status": "COMPLETED",
  "discrepanciesFound": 0,
  "adjustmentsMade": [],
  "reconciliatedAt": "2025-09-01T10:45:00Z"
}
```

### ğŸ›¡ï¸ **Admin APIs (DLQ Management)**

#### **5. GestÃ£o do Dead Letter Queue**

```bash
# EstatÃ­sticas do DLQ
curl -X GET "http://localhost:8081/api/v1/admin/dlq/stats" \
  -H "Accept: application/json" | jq

# Resposta esperada:
{
  "totalEvents": 150,
  "pendingEvents": 5,
  "processingEvents": 2,
  "succeededEvents": 140,
  "failedEvents": 3,
  "oldestPendingEvent": "2025-09-01T09:30:00Z",
  "lastProcessedAt": "2025-09-01T10:30:00Z",
  "averageRetryTime": "PT2M30S",
  "successRate": 95.5
}
```

```bash
# Listar eventos pendentes
curl -X GET "http://localhost:8081/api/v1/admin/dlq/events?status=PENDING&limit=10" \
  -H "Accept: application/json" | jq

# ForÃ§ar processamento da fila
curl -X POST "http://localhost:8081/api/v1/admin/dlq/process-queue" \
  -H "Content-Type: application/json" \
  -d '{"maxEvents": 50, "forceRetry": true}' | jq

# Limpar eventos antigos
curl -X DELETE "http://localhost:8081/api/v1/admin/dlq/cleanup?olderThanDays=7" \
  -H "Accept: application/json" | jq
```

### ğŸ“Š **CenÃ¡rio Completo: Jornada do Cliente**

```bash
#!/bin/bash
echo "ğŸ›’ Simulando jornada completa do cliente..."

# 1. Cliente consulta produtos disponÃ­veis
echo "1ï¸âƒ£ Consultando produtos..."
PRODUCTS=$(curl -s "http://localhost:8081/api/v1/store/STORE-001/inventory/products")
SKU=$(echo $PRODUCTS | jq -r '.[0].sku')
echo "ğŸ“¦ Produto selecionado: $SKU"

# 2. Cliente adiciona produto ao carrinho (reserva)
echo "2ï¸âƒ£ Adicionando ao carrinho..."
RESERVATION=$(curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/$SKU/reserve" \
  -H "Content-Type: application/json" \
  -d '{
    "quantity": 1,
    "customerId": "customer-demo-001",
    "reservationDuration": "PT30M"
  }')

RESERVATION_ID=$(echo $RESERVATION | jq -r '.reservationId')
echo "ğŸ« Reserva criada: $RESERVATION_ID"

# 3. Verificar estoque foi reduzido
echo "3ï¸âƒ£ Verificando estoque apÃ³s reserva..."
curl -s "http://localhost:8081/api/v1/store/STORE-001/inventory/products/$SKU" | jq '.availableQuantity'

# 4. Cliente finaliza compra (commit)
echo "4ï¸âƒ£ Finalizando compra..."
COMMIT=$(curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/$SKU/commit" \
  -H "Content-Type: application/json" \
  -d "{
    \"reservationId\": \"$RESERVATION_ID\",
    \"customerId\": \"customer-demo-001\",
    \"saleId\": \"sale-$(date +%s)\"
  }")

echo "âœ… Compra confirmada: $(echo $COMMIT | jq -r '.commitId')"

# 5. Verificar inventÃ¡rio global foi atualizado
echo "5ï¸âƒ£ Verificando inventÃ¡rio global..."
sleep 2  # Aguardar evento ser processado
curl -s "http://localhost:8082/api/v1/inventory/global/$SKU" | jq '.totalQuantity'

echo "ğŸ‰ Jornada completa realizada com sucesso!"
```

### ğŸ“± **ImportaÃ§Ã£o Postman**

1. **Baixar arquivos**:
   - `postman-collection.json` - Collection completa
   - `postman-environment.json` - VariÃ¡veis de ambiente

2. **Importar no Postman**:
   ```
   File â†’ Import â†’ Upload Files â†’ Selecionar arquivos
   ```

3. **Configurar environment**:
   ```
   Environments â†’ Management System â†’ Set as active
   ```

4. **Executar testes**:
   ```
   Collections â†’ Management System â†’ Run Collection
   ```

## ğŸ§ª Testes Automatizados

### ğŸš€ **Scripts de Teste DisponÃ­veis**

| **Script** | **DescriÃ§Ã£o** | **Tempo** | **Cobertura** |
|------------|---------------|-----------|---------------|
| `./scripts/test-basic.sh` | âœ… Health checks + APIs bÃ¡sicas | ~30s | Smoke tests |
| `./scripts/test-complete.sh` | ğŸ”„ Suite completa de integraÃ§Ã£o | ~3min | E2E completo |
| `./scripts/test-api.sh` | ğŸ“¡ Testes especÃ­ficos de API | ~1min | Funcional |
| `./scripts/test-resilience.sh` | ğŸ›¡ï¸ Testes de resiliÃªncia DLQ | ~4min | Sistema DLQ |
| `./scripts/test-sync-realtime.sh` | âš¡ SincronizaÃ§Ã£o em tempo real | ~2min | Eventos |
| `./scripts/diagnostic.sh` | ğŸ” DiagnÃ³stico completo do sistema | ~1min | Health |

### ğŸ¯ **Executar Testes por CenÃ¡rio**

#### **1. VerificaÃ§Ã£o RÃ¡pida (CI/CD)**
```bash
# Smoke test rÃ¡pido para validaÃ§Ã£o bÃ¡sica
./scripts/test-basic.sh

# SaÃ­da esperada:
# ğŸª Store Service Health Check: âœ… PASSED
# ğŸ¢ Central Service Health Check: âœ… PASSED  
# ğŸ’¾ PostgreSQL Connection: âœ… PASSED
# ğŸ—„ï¸ Redis Connection: âœ… PASSED
# ğŸ“¨ Kafka Connection: âœ… PASSED
# ğŸ“Š Prometheus Metrics: âœ… PASSED
# ğŸ“ˆ Grafana Dashboard: âœ… PASSED
# 
# âœ… All basic tests PASSED (7/7) - System is healthy!
```

#### **2. ValidaÃ§Ã£o Completa (Pre-deployment)**
```bash
# ExecuÃ§Ã£o completa para validar release
./scripts/test-complete.sh

# Cobertura:
# - API endpoints (GET, POST, PUT, DELETE)
# - Business logic (reserve â†’ commit â†’ cancel)
# - Integration entre serviÃ§os
# - Event processing
# - Error handling
# - Performance bÃ¡sico
```

#### **3. Teste de ResiliÃªncia (Chaos Engineering)**
```bash
# Simula falhas no Kafka para testar DLQ
./scripts/test-resilience.sh

# Processo:
# 1. ğŸ”§ Para o Kafka container
# 2. ğŸ›¡ï¸ Executa operaÃ§Ãµes (vÃ£o para DLQ)
# 3. âœ… Verifica eventos armazenados
# 4. ğŸ”„ Reinicia Kafka
# 5. ğŸ¤– Aguarda auto-recovery (5min)
# 6. âœ… Valida eventos processados
```

### ğŸ”¬ **Testes UnitÃ¡rios e IntegraÃ§Ã£o**

#### **Store Service**
```bash
cd store-service

# Testes unitÃ¡rios (rÃ¡pidos)
mvn clean test
# âœ… 85+ unit tests
# âœ… 90%+ code coverage
# âœ… < 30s execution time

# Testes de integraÃ§Ã£o (com TestContainers)
mvn clean verify
# âœ… 25+ integration tests
# âœ… Real PostgreSQL container
# âœ… Real Kafka container
# âœ… Real Redis container
# âœ… ~2min execution time

# RelatÃ³rios de cobertura
open target/site/jacoco/index.html
```

#### **Central Inventory Service**
```bash
cd central-inventory-service

# ExecuÃ§Ã£o completa com perfil de teste
mvn clean verify -Ptest-complete

# Cucumber BDD Tests
mvn test -Dtest=CucumberTestRunner
# âœ… 15+ BDD scenarios
# âœ… Given-When-Then format
# âœ… Business-readable tests
```

### ğŸ“Š **Testes de Performance**

#### **Load Testing com curl**
```bash
#!/bin/bash
echo "ğŸš€ Performance Test - Store Service"

# Teste de carga bÃ¡sico
for i in {1..100}; do
  curl -s -w "%{time_total}\n" -o /dev/null \
    "http://localhost:8081/api/v1/store/STORE-001/inventory/products" &
done
wait

# MÃ©tricas esperadas:
# - P50 < 50ms
# - P95 < 200ms  
# - P99 < 500ms
# - 0% error rate
```

#### **Stress Test de ConcorrÃªncia**
```bash
#!/bin/bash
echo "ğŸ”¥ Concurrency Stress Test"

# Simular mÃºltiplas reservas simultÃ¢neas
for i in {1..50}; do
  curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/reserve" \
    -H "Content-Type: application/json" \
    -d "{
      \"quantity\": 1,
      \"customerId\": \"load-test-$i\",
      \"reservationDuration\": \"PT5M\"
    }" &
done
wait

echo "âœ… Verificando consistÃªncia apÃ³s carga..."
# Verificar se nÃ£o hÃ¡ over-reservation
```

### ğŸ­ **Testes End-to-End (E2E)**

#### **CenÃ¡rio 1: Jornada Completa do Cliente**
```bash
#!/bin/bash
# Arquivo: tests/e2e/customer-journey.sh

echo "ğŸ›’ E2E Test: Customer Journey"

# 1. Descoberta de produto
PRODUCTS=$(curl -s "http://localhost:8081/api/v1/store/STORE-001/inventory/products")
assert_http_success "Product listing"

# 2. Consulta detalhada  
PRODUCT_DETAIL=$(curl -s "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001")
assert_http_success "Product detail"
assert_field_exists "$PRODUCT_DETAIL" "availableQuantity"

# 3. Reserva do produto
RESERVATION=$(curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/reserve" \
  -H "Content-Type: application/json" \
  -d '{
    "quantity": 1,
    "customerId": "e2e-customer-001",
    "reservationDuration": "PT30M"
  }')
assert_http_success "Product reservation"
RESERVATION_ID=$(echo $RESERVATION | jq -r '.reservationId')
assert_not_empty "$RESERVATION_ID"

# 4. ValidaÃ§Ã£o no inventÃ¡rio global
sleep 2  # Aguardar evento ser processado
GLOBAL_INVENTORY=$(curl -s "http://localhost:8082/api/v1/inventory/global/NOTEBOOK-001")
assert_http_success "Global inventory check"
assert_field_decreased "$GLOBAL_INVENTORY" "totalAvailableQuantity"

# 5. FinalizaÃ§Ã£o da compra
COMMIT=$(curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001/commit" \
  -H "Content-Type: application/json" \
  -d "{
    \"reservationId\": \"$RESERVATION_ID\",
    \"customerId\": \"e2e-customer-001\",
    \"saleId\": \"e2e-sale-$(date +%s)\"
  }")
assert_http_success "Commit sale"

# 6. VerificaÃ§Ã£o final
FINAL_INVENTORY=$(curl -s "http://localhost:8081/api/v1/store/STORE-001/inventory/products/NOTEBOOK-001")
assert_field_decreased "$FINAL_INVENTORY" "quantity"

echo "âœ… E2E Customer Journey: PASSED"
```

#### **CenÃ¡rio 2: Sistema de ResiliÃªncia**
```bash
#!/bin/bash
# Arquivo: tests/e2e/dlq-resilience.sh

echo "ğŸ›¡ï¸ E2E Test: DLQ Resilience System"

# 1. Estado inicial do DLQ
INITIAL_DLQ=$(curl -s "http://localhost:8081/api/v1/admin/dlq/stats")
INITIAL_PENDING=$(echo $INITIAL_DLQ | jq '.pendingEvents')

# 2. Simular falha no Kafka
echo "ğŸ”§ Stopping Kafka to simulate failure..."
docker-compose stop kafka

# 3. Executar operaÃ§Ãµes durante falha
for i in {1..5}; do
  curl -s -X POST "http://localhost:8081/api/v1/store/STORE-001/inventory/products/SMARTPHONE-001/reserve" \
    -H "Content-Type: application/json" \
    -d "{
      \"quantity\": 1,
      \"customerId\": \"resilience-test-$i\",
      \"reservationDuration\": \"PT30M\"
    }" > /dev/null
done

# 4. Verificar eventos foram para DLQ
AFTER_FAILURE_DLQ=$(curl -s "http://localhost:8081/api/v1/admin/dlq/stats")
CURRENT_PENDING=$(echo $AFTER_FAILURE_DLQ | jq '.pendingEvents')

if [ $CURRENT_PENDING -gt $INITIAL_PENDING ]; then
  echo "âœ… Events correctly stored in DLQ"
else
  echo "âŒ DLQ not working properly"
  exit 1
fi

# 5. Restaurar Kafka
echo "ğŸ”„ Restarting Kafka..."
docker-compose start kafka
sleep 30  # Aguardar Kafka estar pronto

# 6. ForÃ§ar processamento da fila
curl -s -X POST "http://localhost:8081/api/v1/admin/dlq/process-queue" > /dev/null

# 7. Aguardar processamento automÃ¡tico
echo "â³ Waiting for auto-recovery (5 minutes)..."
sleep 300

# 8. Verificar recuperaÃ§Ã£o
FINAL_DLQ=$(curl -s "http://localhost:8081/api/v1/admin/dlq/stats")
FINAL_PENDING=$(echo $FINAL_DLQ | jq '.pendingEvents')
SUCCEEDED_EVENTS=$(echo $FINAL_DLQ | jq '.succeededEvents')

if [ $FINAL_PENDING -eq $INITIAL_PENDING ] && [ $SUCCEEDED_EVENTS -gt 0 ]; then
  echo "âœ… DLQ Auto-recovery: PASSED"
else
  echo "âŒ DLQ Auto-recovery: FAILED"
  exit 1
fi
```

### ğŸ“‹ **Test Coverage Report**

```yaml
Cobertura de Testes:
  Store Service:
    - Unit Tests: 91.5%
    - Integration Tests: 87.2%
    - E2E Tests: 95.0%
    
  Central Service:
    - Unit Tests: 88.3%
    - Integration Tests: 82.7%
    - E2E Tests: 90.0%
    
  Infrastructure:
    - Health Checks: 100%
    - DLQ System: 95.5%
    - Error Handling: 89.1%

Total Test Count:
  - Unit Tests: 156
  - Integration Tests: 47
  - E2E Tests: 23
  - Performance Tests: 12
  - Resilience Tests: 8
  
Execution Time:
  - Quick: 30s (basic tests)
  - Complete: 3min (all tests)
  - Nightly: 15min (full suite + perf)
```

### ğŸ¤– **Continuous Integration**

#### **GitHub Actions Pipeline**
```yaml
# .github/workflows/ci.yml
name: CI Pipeline
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
      redis:
        image: redis:7.2
      kafka:
        image: confluentinc/cp-kafka:7.4.0
        
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-java@v4
      with:
        java-version: '21'
        
    - name: Run Tests
      run: |
        mvn clean verify
        ./scripts/test-basic.sh
        ./scripts/test-complete.sh
        
    - name: Code Coverage
      run: bash <(curl -s https://codecov.io/bash)
```

### ğŸ¯ **Test Execution Strategy**

#### **Development**
```bash
# Durante desenvolvimento
mvn test -Dtest=*Test                    # Unit tests apenas
./scripts/test-basic.sh                  # Smoke test rÃ¡pido
```

#### **Pre-commit**
```bash
# Antes de commit
mvn clean verify                         # Testes completos
./scripts/test-api.sh                    # ValidaÃ§Ã£o API
```

#### **Pre-deployment**
```bash
# Antes de deploy
./scripts/test-complete.sh              # Suite completa
./scripts/test-resilience.sh            # Testes de resiliÃªncia
```

#### **Production Health Check**
```bash
# Monitoramento contÃ­nuo em produÃ§Ã£o
./scripts/diagnostic.sh                 # DiagnÃ³stico geral
curl -f http://prod.domain.com/actuator/health  # Health endpoint
```

## ğŸ”§ ConfiguraÃ§Ã£o e Deployment

### ğŸ³ **Container Infrastructure**

#### **Docker Compose Services**
```yaml
Infraestrutura Base:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    ports: ["2181:2181"]
    volumes: [zookeeper_data, zookeeper_logs]
    
  kafka:
    image: confluentinc/cp-kafka:7.4.0  
    ports: ["9092:9092", "29092:29092"]
    depends_on: [zookeeper]
    volumes: [kafka_data]
    
  postgres:
    image: postgres:15-alpine
    ports: ["5432:5432"]
    volumes: [postgres_data, ./infrastructure/postgres/init]
    environment:
      POSTGRES_DB: inventory_db
      POSTGRES_USER: inventory_user
      
  redis:
    image: redis:7.2-alpine
    ports: ["6379:6379"] 
    command: redis-server --appendonly yes --requirepass inventorypass123
    volumes: [redis_data]

Monitoramento:
  prometheus:
    image: prom/prometheus:v2.47.0
    ports: ["9090:9090"]
    volumes: [./infrastructure/prometheus/prometheus.yml, prometheus_data]
    
  grafana:
    image: grafana/grafana:10.1.0
    ports: ["3000:3000"]
    volumes: [grafana_data, ./infrastructure/grafana]
    environment:
      GF_SECURITY_ADMIN_PASSWORD: grafana123

AplicaÃ§Ãµes:
  store-service:
    build: ./store-service
    ports: ["8081:8081"]
    depends_on: [kafka, redis, postgres]
    environment:
      SPRING_PROFILES_ACTIVE: local
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      
  central-inventory-service:
    build: ./central-inventory-service
    ports: ["8082:8082"] 
    depends_on: [postgres, kafka, redis]
```

### âš™ï¸ **ConfiguraÃ§Ãµes de Ambiente**

#### **Profiles Spring Boot**
```yaml
# application-local.yml (desenvolvimento)
spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/inventory_db
    username: inventory_user
    password: inventory_password
    
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      retries: 5
      acks: all
      
  redis:
    host: localhost
    port: 6379
    password: inventorypass123

# application-docker.yml (containers)  
spring:
  datasource:
    url: jdbc:postgresql://postgres:5432/inventory_db
    
  kafka:
    bootstrap-servers: kafka:29092
    
  redis:
    host: redis
    
# application-prod.yml (produÃ§Ã£o)
spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    security:
      protocol: SASL_SSL
      
  datasource:
    url: jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
    username: ${DB_USER}
    password: ${DB_PASSWORD}
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
```

### ğŸ—ï¸ **Build e Deployment**

#### **Maven Multi-Module Build**
```xml
<!-- parent pom.xml -->
<modules>
    <module>store-service</module>
    <module>central-inventory-service</module>
</modules>

<!-- Comandos de build -->
mvn clean compile                    # CompilaÃ§Ã£o
mvn clean test                      # Testes unitÃ¡rios  
mvn clean verify                    # Testes de integraÃ§Ã£o
mvn clean package                   # Gerar JARs
mvn clean package -DskipTests       # Build rÃ¡pido
```

#### **Docker Build Otimizado**
```dockerfile
# Multi-stage build para reduzir tamanho da imagem
FROM maven:3.9-openjdk-21 AS builder
WORKDIR /app
COPY pom.xml .
COPY src src
RUN mvn clean package -DskipTests

FROM openjdk:21-jre-slim
WORKDIR /app
COPY --from=builder /app/target/*.jar app.jar

# OtimizaÃ§Ãµes JVM
ENV JAVA_OPTS="-Xmx1024m -Xms512m -XX:+UseG1GC -XX:+UseStringDeduplication"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8081/actuator/health || exit 1

EXPOSE 8081
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### âš¡ **Performance Tuning**

#### **JVM Configuration**
```bash
# OtimizaÃ§Ãµes de produÃ§Ã£o
JAVA_OPTS="
  -Xmx2048m -Xms1024m
  -XX:+UseG1GC
  -XX:MaxGCPauseMillis=200
  -XX:+UseStringDeduplication
  -XX:+OptimizeStringConcat
  -Dspring.jpa.hibernate.ddl-auto=validate
  -Dspring.datasource.hikari.maximum-pool-size=20
  -Dspring.kafka.producer.batch-size=32768
  -Dspring.kafka.producer.linger-ms=10
"
```

#### **Database Tuning**
```sql
-- PostgreSQL otimizaÃ§Ãµes
-- postgresql.conf
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
max_connections = 200

-- Ãndices otimizados
CREATE INDEX CONCURRENTLY idx_products_sku_store ON products (sku, store_id);
CREATE INDEX CONCURRENTLY idx_reservations_expires_at ON reservations (expires_at) WHERE status = 'ACTIVE';
CREATE INDEX CONCURRENTLY idx_failed_events_status_created ON failed_events (status, created_at);
```

#### **Kafka Configuration**
```yaml
# kafka optimization
bootstrap-servers: kafka:29092
producer:
  acks: all
  retries: 5
  batch-size: 32768
  linger-ms: 10
  compression-type: lz4
  max-in-flight-requests-per-connection: 5
  enable-idempotence: true
  
consumer:
  auto-offset-reset: earliest
  enable-auto-commit: false
  max-poll-records: 100
  fetch-min-size: 1024
```

## ğŸ“Š Sistema de Monitoramento e Observabilidade

### ğŸ›ï¸ **Dashboards Grafana Configurados**

#### **1. Application Performance Monitoring**
```yaml
MÃ©tricas de AplicaÃ§Ã£o:
  - ğŸ“ˆ Request Rate (RPS)
  - â±ï¸ Response Time (P50, P95, P99)
  - ğŸš¨ Error Rate por endpoint
  - ğŸ’¾ Memory Usage (Heap/Non-heap)
  - ğŸ”„ GC Performance
  - ğŸƒâ€â™‚ï¸ Thread Pool Status

Alertas Configurados:
  - ğŸš¨ Response time > 500ms
  - ğŸš¨ Error rate > 5%
  - ğŸš¨ Memory usage > 85%
  - ğŸš¨ Service unavailable
```

#### **2. Business Intelligence Dashboard**
```yaml
KPIs de NegÃ³cio:
  - ğŸ›’ Reservas por minuto
  - ğŸ’° Vendas confirmadas
  - âŒ Cancelamentos por motivo
  - ğŸ“Š ConversÃ£o reserva â†’ venda
  - ğŸª Performance por loja
  - ğŸ“ˆ Top produtos

MÃ©tricas Customizadas:
  - inventory_operations_total{type="reserve|commit|cancel"}
  - dlq_events_total{status="pending|succeeded|failed"}
  - concurrent_reservations_gauge
  - optimistic_lock_failures_total
```

#### **3. Infrastructure Monitoring**
```yaml
PostgreSQL:
  - ğŸ”— Active Connections
  - ğŸ“Š Query Performance  
  - ğŸ’¾ Database Size
  - ğŸ”„ Replication Lag
  - ğŸš¨ Lock Conflicts

Redis:
  - ğŸ’¾ Memory Usage
  - ğŸ“Š Hit/Miss Ratio
  - ğŸ”— Client Connections
  - âš¡ Command Latency

Kafka:
  - ğŸ“¨ Message Throughput
  - ğŸ“Š Consumer Lag
  - ğŸ”„ Topic Partitions
  - ğŸ’¾ Disk Usage
```

#### **4. DLQ (Dead Letter Queue) Monitoring**
```yaml
Sistema de ResiliÃªncia:
  - ğŸ“‹ Eventos Pendentes por Status
  - â±ï¸ Tempo de Retry
  - ğŸ“Š Taxa de RecuperaÃ§Ã£o
  - ğŸ”„ Auto-Recovery Performance
  - ğŸš¨ Alertas de Volume Alto

Queries Prometheus:
  - dlq_events_total{status="pending"}
  - dlq_retry_duration_seconds
  - dlq_recovery_rate{success="true"}
  - circuit_breaker_state{name="kafka-publisher"}
```

### ğŸ” **Queries Prometheus Ãšteis**

```promql
# Performance da API
rate(http_requests_total[1m])

# LatÃªncia P95 por endpoint
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
) by (uri)

# Taxa de erro por serviÃ§o
sum(rate(http_requests_total{status=~"5.."}[1m])) by (service) /
sum(rate(http_requests_total[1m])) by (service) * 100

# Eventos no DLQ por tipo
dlq_events_total{status="pending"} by (event_type)

# Uso de memÃ³ria da JVM
jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100

# ConexÃµes ativas do banco
hikaricp_connections_active{pool="primary"}

# Circuit Breaker status
circuit_breaker_state{name="kafka-publisher",state="open"}
```

## ğŸ“š DocumentaÃ§Ã£o

### Documentos Principais

| Documento | DescriÃ§Ã£o |
|-----------|-----------|
| [INSTALLATION.md](docs/INSTALLATION.md) | Guia detalhado de instalaÃ§Ã£o e configuraÃ§Ã£o |
| [API.md](docs/API.md) | DocumentaÃ§Ã£o completa das APIs com exemplos |
| [TESTING.md](docs/TESTING.md) | Guia completo de testes (unitÃ¡rios, integraÃ§Ã£o, E2E) |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Arquitetura detalhada, padrÃµes e decisÃµes tÃ©cnicas |

### Swagger UI

- **Store Service**: http://localhost:8081/store-service/swagger-ui.html
- **Central Service**: http://localhost:8082/central-inventory-service/swagger-ui.html

## ğŸš¨ Troubleshooting

### Problemas Comuns

#### Portas em Uso
```bash
# Verificar portas
lsof -i :8081
lsof -i :8082

# Parar processos
kill -9 <PID>
```

#### Containers NÃ£o Inicializam
```bash
# Ver logs
docker-compose logs <service-name>

# ForÃ§ar recriaÃ§Ã£o
docker-compose up --build --force-recreate
```

#### Conectividade Entre ServiÃ§os
```bash
# Testar conectividade
docker-compose exec store-service ping postgres
docker-compose exec store-service ping kafka
```

### Coleta de InformaÃ§Ãµes para Suporte
```bash
# VersÃµes
docker --version
docker-compose --version

# Status dos containers
docker-compose ps

# Logs recentes
docker-compose logs --tail=100 --timestamps

# Recursos
docker stats --no-stream
```

## ğŸ›‘ Parar Sistema

```bash
# Parar serviÃ§os
docker-compose down

# Parar e limpar dados (âš ï¸ remove volumes)
docker-compose down -v

# Limpeza completa
docker-compose down --rmi all -v
```

## ğŸ”„ Desenvolvimento

### Estrutura do Projeto
```
management-system/
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o detalhada
â”œâ”€â”€ scripts/                 # Scripts de teste e utilitÃ¡rios
â”œâ”€â”€ store-service/           # MicroserviÃ§o da loja
â”œâ”€â”€ central-inventory-service/ # MicroserviÃ§o central
â”œâ”€â”€ infrastructure/          # ConfiguraÃ§Ãµes de infra (Prometheus, Grafana)
â”œâ”€â”€ docker-compose.yml       # OrquestraÃ§Ã£o completa
â”œâ”€â”€ postman-collection.json  # ColeÃ§Ã£o Postman
â””â”€â”€ README.md               # Este arquivo
```

### Contribuindo

1. Fork o projeto
2. Crie uma feature branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Crie um Pull Request

### Executar Localmente (Desenvolvimento)

```bash
# Subir apenas infraestrutura
docker-compose up -d postgres redis kafka zookeeper

# Executar aplicaÃ§Ãµes
cd store-service && mvn spring-boot:run
cd central-inventory-service && mvn spring-boot:run
```

## ğŸ¯ Roadmap e Funcionalidades Futuras

### ğŸ“… **VersÃ£o 2.0 - Q1 2025**
- [ ] ğŸ” **AutenticaÃ§Ã£o e AutorizaÃ§Ã£o JWT**
  - OAuth 2.0 / OpenID Connect
  - Role-Based Access Control (RBAC)
  - API Keys para parceiros externos

- [ ] âš¡ **Rate Limiting e Throttling**
  - Rate limiting por cliente/API key
  - Circuit breaker avanÃ§ado
  - Adaptive throttling

- [ ] ğŸ” **Distributed Tracing**
  - Jaeger integration
  - Correlation IDs completos
  - Performance profiling

### ğŸ“… **VersÃ£o 2.1 - Q2 2025**
- [ ] ğŸ“Š **Event Sourcing Completo**
  - Event Store dedicado
  - Replay de eventos
  - CQRS avanÃ§ado

- [ ] ğŸŒ **Multi-tenant Support**
  - Isolamento por tenant
  - ConfiguraÃ§Ãµes por cliente
  - Billing por uso

- [ ] â˜ï¸ **Cloud Native**
  - Kubernetes deployment
  - Helm charts
  - Service mesh (Istio)

### ğŸ“… **VersÃ£o 3.0 - Q3 2025**
- [ ] ğŸ¤– **Machine Learning**
  - PrevisÃ£o de demanda
  - OtimizaÃ§Ã£o de estoque
  - DetecÃ§Ã£o de anomalias

- [ ] ğŸ”„ **CI/CD Pipeline**
  - GitHub Actions
  - Automated testing
  - Blue-green deployment

- [ ] ğŸŒ **GraphQL API**
  - Complementar REST
  - Real-time subscriptions
  - Schema federation

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **MIT License**.

```
MIT License

Copyright (c) 2025 Management System Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

## ğŸ¤ ContribuiÃ§Ã£o

### **Como Contribuir**

1. **Fork o projeto**
   ```bash
   git clone https://github.com/seu-usuario/management-system.git
   cd management-system
   ```

2. **Criar feature branch**
   ```bash
   git checkout -b feature/nova-funcionalidade
   ```

3. **Implementar e testar**
   ```bash
   # Implementar mudanÃ§as
   mvn clean test                    # Testes unitÃ¡rios
   ./scripts/test-complete.sh        # Testes de integraÃ§Ã£o
   ```

4. **Commit e Push**
   ```bash
   git commit -am 'Adiciona nova funcionalidade: X'
   git push origin feature/nova-funcionalidade
   ```

5. **Criar Pull Request**
   - Descrever funcionalidade implementada
   - Incluir testes e documentaÃ§Ã£o
   - Aguardar review da equipe

### **PadrÃµes de CÃ³digo**

```yaml
Java:
  - Java 21 features quando apropriado
  - Spring Boot conventions
  - Hexagonal architecture patterns
  - Comprehensive JavaDoc

Testes:
  - Unit tests: JUnit 5 + Mockito
  - Integration tests: TestContainers
  - BDD tests: Cucumber
  - Minimum 80% code coverage

DocumentaÃ§Ã£o:
  - README.md atualizado
  - API documentation (OpenAPI)
  - Architectural decisions recorded
  - Docker documentation
```

## ğŸ†˜ Suporte e Comunidade

### **Canais de Suporte**

| **Canal** | **DescriÃ§Ã£o** | **Tempo de Resposta** |
|-----------|---------------|----------------------|
| ğŸ“‹ **GitHub Issues** | Bugs e feature requests | 24-48h |
| ğŸ’¬ **Discord** | Chat em tempo real | Imediato |
| ğŸ“§ **Email** | Suporte comercial | 4-8h (horÃ¡rio comercial) |
| ğŸ“š **Wiki** | DocumentaÃ§Ã£o detalhada | Self-service |

### **Links Ãšteis**

- ğŸ  **Homepage**: [management-system.dev](https://management-system.dev)
- ï¿½ **Documentation**: [docs.management-system.dev](https://docs.management-system.dev)
- ğŸ› **Issue Tracker**: [GitHub Issues](https://github.com/management-system/issues)
- ğŸ’¬ **Community**: [Discord Server](https://discord.gg/management-system)
- ğŸ“§ **Contact**: [contato@management-system.dev](mailto:contato@management-system.dev)

### **EstatÃ­sticas do Projeto**

```yaml
MÃ©tricas de Desenvolvimento:
  - â­ Stars: 1.2k+
  - ğŸ´ Forks: 280+
  - ğŸ› Issues: 12 open / 180 closed
  - ï¿½ Contributors: 25+
  - ğŸ“Š Code Coverage: 85%+
  - ğŸš€ Production Users: 50+ companies

Stack Popularity:
  - Java 21: Cutting-edge features
  - Spring Boot 3.x: Latest enterprise patterns
  - Kafka: Industry standard for streaming
  - PostgreSQL: Most advanced open source DB
  - Docker: Universal containerization
```

---

<div align="center">

### ğŸ‰ **Obrigado por usar o Management System!**

**Desenvolvido com â¤ï¸ usando Spring Boot, Apache Kafka, PostgreSQL e muito â˜•**

[â­ Star no GitHub](https://github.com/management-system) â€¢ 
[ğŸ“– DocumentaÃ§Ã£o](https://docs.management-system.dev) â€¢ 
[ğŸ› Reportar Bug](https://github.com/management-system/issues) â€¢ 
[ğŸ’¡ Sugerir Feature](https://github.com/management-system/issues/new)

</div>
